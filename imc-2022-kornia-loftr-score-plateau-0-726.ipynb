{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0f4396",
   "metadata": {
    "papermill": {
     "duration": 0.014866,
     "end_time": "2022-05-08T14:14:29.374592",
     "exception": false,
     "start_time": "2022-05-08T14:14:29.359726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "credit :[this notebook by ammarali32](https://www.kaggle.com/code/ammarali32/imc-2022-kornia-loftr-from-0-533-to-0-721) and followers...\n",
    "\n",
    "\n",
    "### In this experiment, with our dataset, the pretrained  LoFTR outdoors model seems to reach a plateau at 0.726."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40471b96",
   "metadata": {
    "papermill": {
     "duration": 0.013379,
     "end_time": "2022-05-08T14:14:29.404170",
     "exception": false,
     "start_time": "2022-05-08T14:14:29.390791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ***Install Libs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894f20ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T14:14:29.439834Z",
     "iopub.status.busy": "2022-05-08T14:14:29.439065Z",
     "iopub.status.idle": "2022-05-08T14:14:46.752022Z",
     "shell.execute_reply": "2022-05-08T14:14:46.751393Z",
     "shell.execute_reply.started": "2022-05-08T14:11:50.924447Z"
    },
    "papermill": {
     "duration": 17.334393,
     "end_time": "2022-05-08T14:14:46.752179",
     "exception": false,
     "start_time": "2022-05-08T14:14:29.417786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#dry_run = False\n",
    "!pip install ../input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\n",
    "!pip install ../input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ad6a9",
   "metadata": {
    "papermill": {
     "duration": 0.014666,
     "end_time": "2022-05-08T14:14:46.782328",
     "exception": false,
     "start_time": "2022-05-08T14:14:46.767662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ***Import dependencies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716fb21b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T14:14:46.817206Z",
     "iopub.status.busy": "2022-05-08T14:14:46.816468Z",
     "iopub.status.idle": "2022-05-08T14:14:48.736447Z",
     "shell.execute_reply": "2022-05-08T14:14:48.735813Z",
     "shell.execute_reply.started": "2022-05-08T14:12:10.320662Z"
    },
    "papermill": {
     "duration": 1.939637,
     "end_time": "2022-05-08T14:14:48.736577",
     "exception": false,
     "start_time": "2022-05-08T14:14:46.796940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "from glob import glob\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import kornia\n",
    "from kornia_moons.feature import *\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "246ac788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T14:14:48.773716Z",
     "iopub.status.busy": "2022-05-08T14:14:48.772817Z",
     "iopub.status.idle": "2022-05-08T14:14:48.820592Z",
     "shell.execute_reply": "2022-05-08T14:14:48.821066Z",
     "shell.execute_reply.started": "2022-05-08T14:12:11.363354Z"
    },
    "papermill": {
     "duration": 0.068907,
     "end_time": "2022-05-08T14:14:48.821205",
     "exception": false,
     "start_time": "2022-05-08T14:14:48.752298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/imcutils\")\n",
    "from imc_metric import EvaluateSubmission, ReadCovisibilityData, FlattenMatrix, LoadCalibration\n",
    "\n",
    "sys.path.append(\"../input/super-glue-pretrained-network\")\n",
    "from models.matching import Matching as SuperGlue\n",
    "from models.utils import (compute_pose_error, compute_epipolar_error,\n",
    "                          estimate_pose, make_matching_plot,\n",
    "                          error_colormap, AverageTimer, pose_auc, read_image,\n",
    "                          rotate_intrinsics, rotate_pose_inplane,\n",
    "                          scale_intrinsics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d318a7ab",
   "metadata": {
    "papermill": {
     "duration": 0.01456,
     "end_time": "2022-05-08T14:14:48.851096",
     "exception": false,
     "start_time": "2022-05-08T14:14:48.836536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ***Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ac95414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T14:14:48.948136Z",
     "iopub.status.busy": "2022-05-08T14:14:48.947483Z",
     "iopub.status.idle": "2022-05-08T14:14:53.229029Z",
     "shell.execute_reply": "2022-05-08T14:14:53.229455Z",
     "shell.execute_reply.started": "2022-05-08T14:12:11.422656Z"
    },
    "papermill": {
     "duration": 4.36357,
     "end_time": "2022-05-08T14:14:53.229644",
     "exception": false,
     "start_time": "2022-05-08T14:14:48.866074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoFTR(\n",
       "  (backbone): ResNetFPN_8_2(\n",
       "    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 196, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(196, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 196, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(196, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(196, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(196, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(196, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3_outconv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (layer2_outconv): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (layer2_outconv2): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Conv2d(256, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (layer1_outconv): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (layer1_outconv2): Sequential(\n",
       "      (0): Conv2d(196, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Conv2d(196, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (pos_encoding): PositionEncodingSine()\n",
       "  (loftr_coarse): LocalFeatureTransformer(\n",
       "    (layers): ModuleList(\n",
       "      (0): LoFTREncoderLayer(\n",
       "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (attention): LinearAttention()\n",
       "        (merge): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): LoFTREncoderLayer(\n",
       "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (attention): LinearAttention()\n",
       "        (merge): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): LoFTREncoderLayer(\n",
       "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (attention): LinearAttention()\n",
       "        (merge): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): LoFTREncoderLayer(\n",
       "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (attention): LinearAttention()\n",
       "        (merge): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): LoFTREncoderLayer(\n",
       "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (attention): LinearAttention()\n",
       "        (merge): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): LoFTREncoderLayer(\n",
       "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (attention): LinearAttention()\n",
       "        (merge): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): LoFTREncoderLayer(\n",
       "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (attention): LinearAttention()\n",
       "        (merge): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): LoFTREncoderLayer(\n",
       "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (attention): LinearAttention()\n",
       "        (merge): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (coarse_matching): CoarseMatching()\n",
       "  (fine_preprocess): FinePreprocess(\n",
       "    (down_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (merge_feat): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (loftr_fine): LocalFeatureTransformer(\n",
       "    (layers): ModuleList(\n",
       "      (0): LoFTREncoderLayer(\n",
       "        (q_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (k_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (v_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (attention): LinearAttention()\n",
       "        (merge): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): LoFTREncoderLayer(\n",
       "        (q_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (k_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (v_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (attention): LinearAttention()\n",
       "        (merge): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fine_matching): FineMatching()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# LoFTR\n",
    "matcher = KF.LoFTR(pretrained=None)\n",
    "matcher.load_state_dict(torch.load(\"../input/kornia-loftr/loftr_outdoor.ckpt\")['state_dict'])\n",
    "matcher = matcher.to(device)\n",
    "matcher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01bd55e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T14:14:53.264813Z",
     "iopub.status.busy": "2022-05-08T14:14:53.264061Z",
     "iopub.status.idle": "2022-05-08T14:14:54.160613Z",
     "shell.execute_reply": "2022-05-08T14:14:54.161220Z",
     "shell.execute_reply.started": "2022-05-08T14:12:14.206535Z"
    },
    "papermill": {
     "duration": 0.916567,
     "end_time": "2022-05-08T14:14:54.161415",
     "exception": false,
     "start_time": "2022-05-08T14:14:53.244848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n"
     ]
    }
   ],
   "source": [
    "# Super Glue\n",
    "config = {\n",
    "    \"superpoint\": {\n",
    "        \"nms_radius\": 4,\n",
    "        \"keypoint_threshold\": 0.005,\n",
    "        \"max_keypoints\": 1024\n",
    "    },\n",
    "    \"superglue\": {\n",
    "        \"weights\": \"outdoor\",\n",
    "        \"sinkhorn_iterations\": 20,\n",
    "        \"match_threshold\": 0.2,\n",
    "    }\n",
    "}\n",
    "superglue = SuperGlue(config).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fac3c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T14:14:54.204584Z",
     "iopub.status.busy": "2022-05-08T14:14:54.204056Z",
     "iopub.status.idle": "2022-05-08T14:14:54.207726Z",
     "shell.execute_reply": "2022-05-08T14:14:54.207315Z",
     "shell.execute_reply.started": "2022-05-08T14:12:14.468929Z"
    },
    "papermill": {
     "duration": 0.030443,
     "end_time": "2022-05-08T14:14:54.207859",
     "exception": false,
     "start_time": "2022-05-08T14:14:54.177416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match(img_path0, img_path1, matcher, device=device):\n",
    "    img0 = load_torch_image(img_path0)\n",
    "    img1 = load_torch_image(img_path1)\n",
    "        \n",
    "    input_dict = {\"image0\": K.color.rgb_to_grayscale(img0).to(device), \n",
    "                  \"image1\": K.color.rgb_to_grayscale(img1).to(device)}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correspondences = matcher(input_dict)\n",
    "        \n",
    "    mkpts0 = correspondences['keypoints0'].cpu().numpy()\n",
    "    mkpts1 = correspondences['keypoints1'].cpu().numpy()\n",
    "        \n",
    "    return mkpts0, mkpts1\n",
    "\n",
    "def superglue_match(img_path0, img_path1, matcher, device=device):\n",
    "    resize = [-1, ]\n",
    "    resize_float = True\n",
    "    image_1, inp_1, scales_1 = read_image(img_path0, device, resize, 0, resize_float)\n",
    "    image_2, inp_2, scales_2 = read_image(img_path1, device, resize, 0, resize_float)\n",
    "    \n",
    "    pred = matcher({\"image0\": inp_1, \"image1\": inp_2})\n",
    "    pred = {k: v[0].detach().cpu().numpy() for k, v in pred.items()}\n",
    "    kpts1, kpts2 = pred[\"keypoints0\"], pred[\"keypoints1\"]\n",
    "    matches, conf = pred[\"matches0\"], pred[\"matching_scores0\"]\n",
    "    \n",
    "    valid = matches > -1\n",
    "    mkpts1 = kpts1[valid]\n",
    "    mkpts2 = kpts2[matches[valid]]\n",
    "    \n",
    "    return mkpts1, mkpts2\n",
    "\n",
    "def get_F_matrix(mkpts0, mkpts1):\n",
    "    # Make sure we do not trigger an exception here.\n",
    "    if len(mkpts0) > 8:\n",
    "        F, inliers = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.200, 0.9999, 250000)\n",
    "        assert F.shape == (3, 3), 'Malformed F?'\n",
    "    else:\n",
    "        F = np.zeros((3, 3))\n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aedc3ed",
   "metadata": {
    "papermill": {
     "duration": 0.014855,
     "end_time": "2022-05-08T14:14:54.237809",
     "exception": false,
     "start_time": "2022-05-08T14:14:54.222954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ***Utils***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28441d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T14:14:54.275780Z",
     "iopub.status.busy": "2022-05-08T14:14:54.275131Z",
     "iopub.status.idle": "2022-05-08T14:14:54.282972Z",
     "shell.execute_reply": "2022-05-08T14:14:54.283345Z",
     "shell.execute_reply.started": "2022-05-08T14:12:14.487054Z"
    },
    "papermill": {
     "duration": 0.030279,
     "end_time": "2022-05-08T14:14:54.283472",
     "exception": false,
     "start_time": "2022-05-08T14:14:54.253193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = '/kaggle/input/image-matching-challenge-2022/'\n",
    "\n",
    "test_samples = []\n",
    "with open(f'{src}/test.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        # Skip header.\n",
    "        if i == 0:\n",
    "            continue\n",
    "        test_samples += [row]\n",
    "\n",
    "\n",
    "def FlattenMatrix(M, num_digits=8):\n",
    "    '''Convenience function to write CSV files.'''\n",
    "    \n",
    "    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n",
    "\n",
    "\n",
    "def load_torch_image(fname):\n",
    "    img = cv2.imread(fname)\n",
    "    scale = 840 / max(img.shape[0], img.shape[1]) \n",
    "    w = int(img.shape[1] * scale)\n",
    "    h = int(img.shape[0] * scale)\n",
    "    img = cv2.resize(img, (w, h))\n",
    "    img = K.image_to_tensor(img, False).float() /255.\n",
    "    img = K.color.bgr_to_rgb(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909aabcb",
   "metadata": {
    "papermill": {
     "duration": 0.016354,
     "end_time": "2022-05-08T14:14:54.314841",
     "exception": false,
     "start_time": "2022-05-08T14:14:54.298487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ***Parametric Study***\n",
    "\n",
    "|Base|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |||\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|**0.723** |0.726|0.726|0.726|0.726|0.726|0.726|0.726|0.726|0.726|0.725|0.725|0.725|0.725|0.725|0.725|0.723|0.723|0.723|0.723|0.722|0.697|0.653|0.608|\n",
    "|**0.25**|0.19|0.18|0.17|0.195|0.19|0.185|0.18|0.175|0.17|0.18|0.15|0.15|0.018|0.015|0.01|0.2|0.2|0.1|0.05|0.5|1|2|3|\n",
    "|**0.9999**|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|0.9999|\n",
    "|**100000**|300000|300000|300000|250000|250000|250000|250000|250000|250000|200000|300000|250000|200000|200000|200000|150000|250000|150000|150000|200000|200000|200000|200000|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "675f8600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T14:14:54.367524Z",
     "iopub.status.busy": "2022-05-08T14:14:54.347536Z",
     "iopub.status.idle": "2022-05-08T14:14:54.698087Z",
     "shell.execute_reply": "2022-05-08T14:14:54.699167Z",
     "shell.execute_reply.started": "2022-05-08T14:12:14.503596Z"
    },
    "papermill": {
     "duration": 0.36955,
     "end_time": "2022-05-08T14:14:54.699373",
     "exception": false,
     "start_time": "2022-05-08T14:14:54.329823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = [0.18,0.19,0.17, 0.195, 0.19, 0.185, 0.18, 0.175, 0.17, 0.18, 0.15, 0.15, 0.018, 0.015, 0.01, 0.2, 0.2, 0.1, 0.05, 0.5, 1, 2, 3 ]\n",
    "y = [30, 30,30, 25, 25, 25, 25, 25, 25, 20, 30, 25, 20,20, 20, 15, 25, 15, 15, 20, 20, 20, 20]\n",
    "z = [0.726, 0.726,  0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.723, 0.723, 0.723, 0.723, 0.722, 0.697, 0.653, 0.608]\n",
    "\n",
    "# Creating figure\n",
    "fig = plt.figure(figsize = (16, 9))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "color_map = plt.get_cmap('cool')\n",
    "scatter_plot = ax.scatter3D(x, y, z,\n",
    "                            c=z, s=80,\n",
    "                            cmap = color_map)\n",
    "\n",
    "\n",
    "ax.scatter(x, y, z, marker='o', cmap = color_map)\n",
    "# Creating Colorbar \n",
    "plt.colorbar(scatter_plot, shrink=0.55)\n",
    "\n",
    "ax.set_xlabel('X Threshold ')\n",
    "ax.set_ylabel('Y maxIters *10K')\n",
    "ax.set_zlabel('z Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d7c804",
   "metadata": {
    "papermill": {
     "duration": 0.023865,
     "end_time": "2022-05-08T14:14:54.748203",
     "exception": false,
     "start_time": "2022-05-08T14:14:54.724338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Takeaway\n",
    "\n",
    "- In this experiment, with our dataset, the pretrained LoFTR outdoors model seems to reach a plateau at 0.726.\n",
    "- OpenCV indicate that the treshold RANSAC Parameter should be set to 1-3. In our case, going significantly lower allows for a better scores.\n",
    "- The 0.726 scoring plateau seems to be around maxIters above 200000 and Treshold below 0.20 with a confidence parameter at 0.9999."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bbd2cc",
   "metadata": {
    "papermill": {
     "duration": 0.026599,
     "end_time": "2022-05-08T14:14:54.801563",
     "exception": false,
     "start_time": "2022-05-08T14:14:54.774964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ***Inference***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e85dbb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T14:14:54.870283Z",
     "iopub.status.busy": "2022-05-08T14:14:54.869439Z",
     "iopub.status.idle": "2022-05-08T14:15:09.442241Z",
     "shell.execute_reply": "2022-05-08T14:15:09.443180Z",
     "shell.execute_reply.started": "2022-05-08T14:12:14.799691Z"
    },
    "papermill": {
     "duration": 14.61524,
     "end_time": "2022-05-08T14:15:09.443398",
     "exception": false,
     "start_time": "2022-05-08T14:14:54.828158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time:  6.504338502883911  s\n",
      "Running time:  2.9991419315338135  s\n",
      "Running time:  1.3778975009918213  s\n"
     ]
    }
   ],
   "source": [
    "F_dict = {}\n",
    "import time\n",
    "for i, row in enumerate(test_samples):\n",
    "    sample_id, batch_id, image_1_id, image_2_id = row\n",
    "    # Load the images.\n",
    "    st = time.time()\n",
    "    image_1 = load_torch_image(f'{src}/test_images/{batch_id}/{image_1_id}.png').to(device)\n",
    "    image_2 = load_torch_image(f'{src}/test_images/{batch_id}/{image_2_id}.png').to(device)\n",
    "    \n",
    "    #LoFTR\n",
    "    loftr_mkpts0, loftr_mkpts1 = match(f'{src}/test_images/{batch_id}/{image_1_id}.png', f'{src}/test_images/{batch_id}/{image_2_id}.png', matcher, device)\n",
    "    \n",
    "    #SuperGlue\n",
    "    sg_mkpts0, sg_mkpts1 = superglue_match(f'{src}/test_images/{batch_id}/{image_1_id}.png', f'{src}/test_images/{batch_id}/{image_2_id}.png', superglue, device)\n",
    "    \n",
    "    mkpts0 = np.vstack((loftr_mkpts0, sg_mkpts0))\n",
    "    mkpts1 = np.vstack((loftr_mkpts1, sg_mkpts1))\n",
    "    \n",
    "    if len(mkpts0) > 7:\n",
    "        F, inliers = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.200, 0.9999, 250000)\n",
    "        inliers = inliers > 0\n",
    "        assert F.shape == (3, 3), 'Malformed F?'\n",
    "        F_dict[sample_id] = F\n",
    "    else:\n",
    "        F_dict[sample_id] = np.zeros((3, 3))\n",
    "        continue\n",
    "    gc.collect()\n",
    "    nd = time.time()    \n",
    "    if (i < 3):\n",
    "        print(\"Running time: \", nd - st, \" s\")\n",
    "        draw_LAF_matches(\n",
    "        KF.laf_from_center_scale_ori(torch.from_numpy(mkpts0).view(1,-1, 2),\n",
    "                                    torch.ones(mkpts0.shape[0]).view(1,-1, 1, 1),\n",
    "                                    torch.ones(mkpts0.shape[0]).view(1,-1, 1)),\n",
    "\n",
    "        KF.laf_from_center_scale_ori(torch.from_numpy(mkpts1).view(1,-1, 2),\n",
    "                                    torch.ones(mkpts1.shape[0]).view(1,-1, 1, 1),\n",
    "                                    torch.ones(mkpts1.shape[0]).view(1,-1, 1)),\n",
    "        torch.arange(mkpts0.shape[0]).view(-1,1).repeat(1,2),\n",
    "        K.tensor_to_image(image_1),\n",
    "        K.tensor_to_image(image_2),\n",
    "        inliers,\n",
    "        draw_dict={'inlier_color': (0.2, 1, 0.2),\n",
    "                   'tentative_color': None, \n",
    "                   'feature_color': (0.2, 0.5, 1), 'vertical': False})\n",
    "    \n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.write('sample_id,fundamental_matrix\\n')\n",
    "    for sample_id, F in F_dict.items():\n",
    "        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46c793c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T14:15:09.501978Z",
     "iopub.status.busy": "2022-05-08T14:15:09.500442Z",
     "iopub.status.idle": "2022-05-08T14:15:09.505342Z",
     "shell.execute_reply": "2022-05-08T14:15:09.506090Z",
     "shell.execute_reply.started": "2022-05-08T14:12:26.929676Z"
    },
    "papermill": {
     "duration": 0.036369,
     "end_time": "2022-05-08T14:15:09.506291",
     "exception": false,
     "start_time": "2022-05-08T14:15:09.469922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f72470",
   "metadata": {
    "papermill": {
     "duration": 0.026887,
     "end_time": "2022-05-08T14:15:09.563921",
     "exception": false,
     "start_time": "2022-05-08T14:15:09.537034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "    <h2 style=\"color: #022047\"> Thanks for reading ðŸ¤—  </h2>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.944188,
   "end_time": "2022-05-08T14:15:11.311379",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-08T14:14:21.367191",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
